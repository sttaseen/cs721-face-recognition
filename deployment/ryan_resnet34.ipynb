{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d491fb-aa99-465a-9345-4bc1b14321cd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca58784-6705-45c2-88b4-2b5173b6b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9a497-64a4-4d28-8745-6f31efb2a922",
   "metadata": {},
   "source": [
    "## Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444694d4-4487-4b57-9714-233e711eedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Set the seed for reproducibility.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed value to set for random number generation.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Set seed to be 42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac401a3d-c05b-427f-aec2-bc97b70c27f1",
   "metadata": {},
   "source": [
    "## Resnet-34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83252d8c-5ba9-447a-8e09-e7592512a54e",
   "metadata": {},
   "source": [
    "## 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4dd3cf8-b256-4abe-a9ae-3e775c0a6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "best_hyperparams = {'lr': 0.01, 'batch_size': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f15792b-c8ad-450c-8ccd-5be72664b7fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/custom/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m dataset_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/custom/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Load datasets\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(root\u001b[38;5;241m=\u001b[39mdataset_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Get the number of classes\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs721/lib/python3.8/site-packages/torchvision/datasets/folder.py:310\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    304\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m ):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/miniconda3/envs/cs721/lib/python3.8/site-packages/torchvision/datasets/folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    137\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    143\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 145\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[0;32m~/miniconda3/envs/cs721/lib/python3.8/site-packages/torchvision/datasets/folder.py:219\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs721/lib/python3.8/site-packages/torchvision/datasets/folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/custom/train'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create the ResNet34 model and load pretrained weights, excluding the final fc layer\n",
    "def create_resnet_model(num_classes, pretrained_path=None):\n",
    "    model = models.resnet34(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)  # Replace the final layer for the new task\n",
    "    \n",
    "    if pretrained_path:\n",
    "        # Load the pretrained model, but exclude the final fully connected layer weights\n",
    "        state_dict = torch.load(pretrained_path)\n",
    "        # Remove the fc layer weights from the pretrained model\n",
    "        del state_dict['fc.weight']\n",
    "        del state_dict['fc.bias']\n",
    "        # Load the remaining layers\n",
    "        model.load_state_dict(state_dict, strict=False)  # strict=False ignores missing keys\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43636918, 0.38563913, 0.34477144],\n",
    "                         std=[0.29639485, 0.2698132, 0.26158142])\n",
    "])\n",
    "\n",
    "# Set the dataset folder\n",
    "dataset_folder = '../data/custom/'\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=dataset_folder + 'train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=dataset_folder + 'test', transform=transform)\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# Create DataLoader for train and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Path to the pretrained model (.pth file)\n",
    "pretrained_model_path = './resnet_34_pretrained.pth'  # Replace with the correct path\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = create_resnet_model(num_classes, pretrained_path=pretrained_model_path)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # You can modify the learning rate if necessary\n",
    "\n",
    "# Test loop\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation for faster inference\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            preds = outputs.argmax(1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            \n",
    "            # Store predictions and labels for further analysis\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate test loss and accuracy\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = correct_preds / len(test_loader.dataset)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "\n",
    "# Training loop for 20 epochs\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    \n",
    "    # Loop over batches of data\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        correct_preds += (outputs.argmax(1) == labels).sum().item()\n",
    "    \n",
    "    # Calculate training loss and accuracy\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = correct_preds / len(train_loader.dataset)\n",
    "    \n",
    "    # Print results for this epoch\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "    print(f'Testing Model...')\n",
    "    evaluate_model(model, test_loader)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'ryan_bush_resnet34.pth')\n",
    "\n",
    "print(\"Training completed and model saved as 'trained_model.pth'.\")    \n",
    "# Evaluate the model on the test set\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da97fb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0000\n",
      "Saving 0 misclassified images to 'misclassified_images/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Directory to save misclassified images\n",
    "misclassified_dir = 'misclassified_images/'\n",
    "if not os.path.exists(misclassified_dir):\n",
    "    os.makedirs(misclassified_dir)\n",
    "\n",
    "# Function to save and display misclassified images\n",
    "def save_and_display_misclassified_images(misclassified_data):\n",
    "    print(f\"Saving {len(misclassified_data)} misclassified images to '{misclassified_dir}'\")\n",
    "    for i, (image, true_label, pred_label) in enumerate(misclassified_data):\n",
    "        # Save misclassified image\n",
    "        image_path = os.path.join(misclassified_dir, f\"image_{i}_true_{true_label}_pred_{pred_label}.png\")\n",
    "        vutils.save_image(image, image_path)\n",
    "        print(f\"Saved: {image_path}\")\n",
    "    \n",
    "    # Optionally display a few misclassified images\n",
    "    num_display = min(5, len(misclassified_data))  # Display at most 5 images\n",
    "    if num_display > 0:\n",
    "        fig, axes = plt.subplots(1, num_display, figsize=(15, 5))\n",
    "        for i in range(num_display):\n",
    "            image, true_label, pred_label = misclassified_data[i]\n",
    "            image = image.permute(1, 2, 0)  # Convert from (C, H, W) to (H, W, C) for display\n",
    "            image = image.cpu().numpy()\n",
    "            image = (image * 0.26158142 + 0.34477144)  # Un-normalize based on dataset stats\n",
    "\n",
    "            axes[i].imshow(image)\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f\"True: {true_label}, Pred: {pred_label}\")\n",
    "        plt.show()\n",
    "\n",
    "# Test loop to identify misclassified images\n",
    "def evaluate_and_collect_misclassified(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    misclassified_data = []  # To store misclassified images\n",
    "    correct_preds = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "\n",
    "            # Find misclassified images\n",
    "            misclassified_idx = (preds != labels).nonzero(as_tuple=True)[0]\n",
    "            for idx in misclassified_idx:\n",
    "                misclassified_data.append((images[idx].cpu(), labels[idx].item(), preds[idx].item()))\n",
    "\n",
    "            # Collect predictions and labels for metrics\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate test accuracy\n",
    "    test_acc = correct_preds / len(test_loader.dataset)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Save and display misclassified images\n",
    "    save_and_display_misclassified_images(misclassified_data)\n",
    "\n",
    "# Run the evaluation and collect misclassified images\n",
    "evaluate_and_collect_misclassified(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs721",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
